import pandas as pd
import altair as alt
import numpy as np

import re
import joblib

from nodes.vis.md_overview_hm.scripts.utils import is_struc_based

TOKEN = config["token"]


def compute_median_f1(path):
    dataset = re.findall("data/(.*?)/", path)[0]
    return pd\
        .read_csv(path, index_col=0)\
        .apply(np.median)\
        .to_frame(dataset)


def is_imbalanced(path):
    with open(path) as f:
        classes = [int(i.rstrip()) for i in f.readlines()]
        return sum(classes) / len(classes)


rule all:
    input:
         config["html_dir_out"] + "md_overview_hm.json"

rule overview_data:
    input:
        config["metric_dirs_in"]
    output:
        temp(f"data/temp/{TOKEN}/hm_data.csv")
    run:
        paths = [p + "f1.csv" for p in list(input)]

        df_res = pd.DataFrame()
        for p in paths:
            df = pd.read_csv(p, index_col=0)
            df_medians = df.apply(np.median).to_frame("median")
            group = lambda enc: \
                "psekraac" if "lambda-corr" in enc or "g-gap" in enc else enc[:6]
            df_medians["group"] = [group(x) for x in df_medians.index]

            df_tmp = df_medians.groupby(by="group").max()
            df_tmp.columns = [re.findall("data/(.*?)/", p)[0]]
            df_res = pd.concat([df_res, df_tmp], axis=1)

        df_res.fillna(0.0, inplace=True)
        df_res.to_csv(output[0])

rule source_data:
    input:
         f"data/temp/{TOKEN}/hm_data.csv"
    output:
         config["html_dir_out"] + "hm_source_data.json"
    run:
         df_res = pd.read_csv(input[0], index_col=0)

         x, y = np.meshgrid(df_res.columns, df_res.index)

         source = pd.DataFrame({"Dataset": x.ravel(), "Encoding": y.ravel(), "F1": df_res.values.ravel()})

         source["type"] = ["structure based" if is_struc_based(e) else "sequence based" for e in source["Encoding"]]
         source["is_imbalanced"] = source["Dataset"].apply(lambda ds: is_imbalanced(f"data/{ds}/classes.txt"))
         source.sort_values(by="is_imbalanced", inplace=True)

         fields = sorted(source["Dataset"].apply(lambda x: x[:3]).unique())
         fields_dict = dict((k, v) for k, v in zip(fields, range(1, len(fields)+1)))
         source["bio_field"] = source["Dataset"].apply(lambda ds: ds[:3])

         type_dict = {"sequence based": 1, "structure based": 2}
         source["type_field"] = source["type"].apply(lambda t: type_dict[t])

         source.to_json(output[0], orient="records")

rule heatmap_biomedical_application:
    input:
         config["html_dir_out"] + "hm_source_data.json",
    output:
         temp(f"data/temp/{TOKEN}/hm_bio_appl.joblib")
    run:
         source = pd.read_json(input[0])

         sorted_encodings = source\
             .groupby(by="Encoding")\
             .mean().sort_values("F1", ascending=False)\
             .index.to_list()

         first_field = sorted(source["bio_field"].unique())[0]

         hcharts = []
         for b in sorted(source["bio_field"].unique()):
             vcharts = []
             for t in source["type"].unique():
                 df_tmp = source.loc[source["bio_field"] == b, :].loc[source["type"] == t, :]
                 df_tmp.sort_values(by="is_imbalanced", inplace=True)
                 url = input[0].replace("source", f"source_{b}_{t.replace(' ', '')}")
                 df_tmp.to_json(url, orient="records")
                 vcharts += [alt.Chart(url).mark_rect(strokeWidth=5.0).encode(
                         y=alt.Y(
                             'Encoding:N',
                             title=None if not b.startswith("ace") else \
                                 "Sequence-based encodings" if t == "sequence based" else "Structure-based encodings",
                             axis=alt.Axis(labels=True if b == first_field else False,
                                           ticks=True if b == first_field else False),
                             sort=alt.Sort(alt.SortArray(sorted(sorted_encodings)))
                         ),
                         x=alt.Y(
                             'Dataset:N',
                             title=None,
                             axis=alt.Axis(labels=False if t == "sequence based" else True,
                                           ticks=False if t == "sequence based" else True),
                             sort=alt.Sort(alt.SortArray(source["Dataset"].unique()))
                         ),
                         color=alt.condition(alt.datum.F1 == 0, alt.value("white"), alt.Color("F1:Q", title="F1")),
                         tooltip=["Encoding:N", "Dataset:N", "F1:Q", "is_imbalanced:Q"]
                     ).properties(
                         height=500 if t == "sequence based" else 150
                     )
                 ]
             hcharts += [alt.vconcat(*vcharts, spacing=2)]

         joblib.dump(alt.hconcat(*hcharts, spacing=5), output[0])

rule heatmap_imbalanced:
    input:
         config["html_dir_out"] + "hm_source_data.json",
    output:
         temp(f"data/temp/{TOKEN}/hm_imbalanced.joblib")
    run:
         source = pd.read_json(input[0])

         names_imbalanced = source["Dataset"].unique()

         hcharts = []
         for thresholds in [[0.0, 0.35], [0.35, 1.0]]:
             vcharts = []
             for t in source["type"].unique():
                 df_tmp = source.loc[source["type"] == t, :].loc[source["is_imbalanced"].between(*thresholds), :]
                 url = input[0].replace("source", f"source_{t}_{thresholds[0]}")
                 df_tmp.to_json(url, orient="records")
                 vcharts += [alt.Chart(url).mark_rect().encode(
                     y=alt.Y(
                         'Encoding:N',
                         title=None,
                         # title=None if thresholds[1] == 1.0 else \
                         #     "Sequence-based encodings" if t == "sequence based" else "Structure-based encodings",
                         # axis=alt.Axis(labels=False, ticks=False)
                         axis=alt.Axis(labels=False if thresholds[1] == 1.0 else True,
                                       ticks=False if thresholds[1] == 1.0 else True),
                     ),
                     x=alt.X(
                         'Dataset:N',
                         sort=alt.Sort(alt.SortArray(names_imbalanced)),
                         title=None,
                         # title=None if t == "sequence based" else ["Imbalanced", "datasets"] if thresholds[1] == 0.3 else [
                         #     "Balanced", "datasets"],
                         axis=alt.Axis(labels=False if t == "sequence based" else True,
                                       ticks=False if t == "sequence based" else True)
                     ),
                     color=alt.condition(alt.datum.F1 == 0, alt.value("white"), alt.Color("F1:Q", title="F1")),
                     tooltip=["Encoding:N", "Dataset:N", "F1:Q", "is_imbalanced:Q"]
                 ).properties(
                     height=500 if t == "sequence based" else 150
                 )]
             hcharts += [alt.vconcat(*vcharts, spacing=2)]

         joblib.dump(alt.hconcat(*hcharts, spacing=5), output[0])

rule heatmap_ranks:
    input:
         config["html_dir_out"] + "hm_source_data.json",
    output:
         temp(f"data/temp/{TOKEN}/hm_ranks.joblib")
    run:
         def annotate(df):
             df_tmp = df.sort_values("F1", ascending=False)
             df_tmp["rank"] = [i if i < 4 else 4 for i, e in enumerate(df_tmp["F1"], start=1)]
             return df_tmp

         source = pd.read_json(input[0])
         names_imbalanced = source["Dataset"].unique()

         # source = source.drop(source[source["Dataset"]=="hiv_v3"].index)
         # source = source.drop(source[source["Encoding"]=="qsar"].index)
         source = source.groupby("Dataset").apply(annotate).reset_index(drop=True)

         hcharts = []
         for thresholds in [[0.0, 0.35], [0.35, 1.0]]:
             vcharts = []
             for t in source["type"].unique():
                 df_tmp = source.loc[source["type"] == t, :].loc[source["is_imbalanced"].between(*thresholds), :]
                 url = input[0].replace("source", f"ranks_source_{t}_{thresholds[0]}")
                 df_tmp.to_json(url, orient="records")
                 vcharts += [alt.Chart(url).mark_rect().encode(
                     y=alt.Y(
                         'Encoding:N',
                         title=None,
                         axis=alt.Axis(labels=False if thresholds[1] == 1.0 else True,
                                       ticks=False if thresholds[1] == 1.0 else True),
                     ),
                     x=alt.X(
                         'Dataset:N',
                         sort=alt.Sort(alt.SortArray(names_imbalanced)),
                         title=None,
                         axis=alt.Axis(labels=False if t == "sequence based" else True,
                                       ticks=False if t == "sequence based" else True)
                     ),
                     color=alt.condition(
                         alt.datum.rank == 4,
                         alt.value("white"),
                         alt.Color(
                             "rank:N",
                             title="Rank",
                             scale=alt.Scale(domain=[1, 2 ,3], range=["#353535", "#888888", "#d4d4d4"]),
                             legend=alt.Legend(values=[1, 2, 3])
                         )
                     ),
                     tooltip="F1:Q"
                 ).properties(
                     height=500 if t == "sequence based" else 150
                 )]
             hcharts += [alt.vconcat(*vcharts, spacing=2)]

         joblib.dump(alt.hconcat(*hcharts, spacing=5), output[0])

rule concat_heatmaps:
    input:
         f"data/temp/{TOKEN}/hm_bio_appl.joblib",
         f"data/temp/{TOKEN}/hm_imbalanced.joblib",
         f"data/temp/{TOKEN}/hm_ranks.joblib"
    output:
         config["html_dir_out"] + "md_overview_hm.json"
    run:
         hm_bio = joblib.load(input[0])
         hm_imb = joblib.load(input[1])
         hm_ran = joblib.load(input[2])

         chart = alt.vconcat(hm_bio, hm_imb, hm_ran)

         with open(output[0], "w") as f:
             f.write(chart.to_json(indent=None))
             f.flush()
