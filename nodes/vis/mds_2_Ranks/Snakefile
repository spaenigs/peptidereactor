import pandas as pd
import altair as alt
import numpy as np

import re
import joblib

from nodes.vis.mds_1_Overview.scripts.utils import is_struc_based

TOKEN = config["token"]


def compute_median_f1(path):
    dataset = re.findall("data/(.*?)/", path)[0]
    return pd\
        .read_csv(path, index_col=0)\
        .apply(np.median)\
        .to_frame(dataset)


def is_imbalanced(path):
    with open(path) as f:
        classes = [int(i.rstrip()) for i in f.readlines()]
        return sum(classes) / len(classes)


rule all:
    input:
         config["html_dir_out"] + "mds_2_Ranks.json"

rule overview_data:
    input:
        config["metric_dirs_in"]
    output:
        temp(f"data/temp/{TOKEN}/hm_data.csv"),
        temp(f"data/temp/{TOKEN}/hm_data_names.csv")
    run:
        paths = [p + "f1.csv" for p in list(input)]

        df_res = pd.DataFrame()
        df_names = pd.DataFrame()
        for p in paths:
            df = pd.read_csv(p, index_col=0)
            df_medians = df.apply(np.median).to_frame("median")
            group = lambda enc: \
                "psekraac" if "lambda-corr" in enc or "g-gap" in enc else enc[:6]
            df_medians["group"] = [group(x) for x in df_medians.index]

            df_tmp = df_medians.groupby(by="group").max()
            dataset = re.findall("data/(.*?)/", p)[0]
            df_tmp.columns = [dataset]

            df_medians["encoding_max"] = df_medians.index
            df_medians = df_medians.groupby(by="group").max()
            df_names_tmp = pd.DataFrame({dataset: df_medians["encoding_max"]})

            df_names = pd.concat([df_names, df_names_tmp], axis=1)
            df_res = pd.concat([df_res, df_tmp], axis=1)

        df_res.to_csv(output[0])

        df_names.to_csv(output[1])

rule source_data:
    input:
         f"data/temp/{TOKEN}/hm_data.csv",
         f"data/temp/{TOKEN}/hm_data_names.csv"
    output:
         config["html_dir_out"] + "hm_source_data.json"
    run:
         df_res = pd.read_csv(input[0], index_col=0)
         df_names = pd.read_csv(input[1], index_col=0)

         x, y = np.meshgrid(df_res.columns, df_res.index)

         source = pd.DataFrame({
             "Dataset": x.ravel(),
             "Encoding": y.ravel(),
             "Encoding_max": df_names.values.ravel(),
             "F1": df_res.values.ravel()
         })

         source["type"] = ["structure based" if is_struc_based(e) else "sequence based" for e in source["Encoding"]]
         source["is_imbalanced"] = source["Dataset"].apply(lambda ds: is_imbalanced(f"data/{ds}/classes.txt"))
         source.sort_values(by="is_imbalanced", inplace=True)

         fields = sorted(source["Dataset"].apply(lambda x: x[:3]).unique())
         fields_dict = dict((k, v) for k, v in zip(fields, range(1, len(fields)+1)))
         source["bio_field"] = source["Dataset"].apply(lambda ds: ds[:3])

         type_dict = {"sequence based": 1, "structure based": 2}
         source["type_field"] = source["type"].apply(lambda t: type_dict[t])

         source["missing"] = source["F1"].apply(lambda f1: True if np.isnan(f1) else False)

         source.to_json(output[0], orient="records")


rule heatmap_ranks:
    input:
         config["html_dir_out"] + "hm_source_data.json",
    output:
         temp(f"data/temp/{TOKEN}/hm_ranks.joblib")
    script:
          "scripts/hm_ran.py"

rule concat_heatmaps:
    input:
         f"data/temp/{TOKEN}/hm_ranks.joblib"
    output:
         config["html_dir_out"] + "mds_2_Ranks.json"
    run:
         hm_ran = joblib.load(input[0])

         chart = alt.vconcat(
             hm_ran,
             title=alt.TitleParams(
                 text=[
                     "Performance of encoding groups. Color coding corresponds to the ranks of encodings across",
                     "datasets. The x-axis is organized by sequence- and structure-based encodings and the y-axis",
                     "is sorted by class balance (cut-off 0.35). Groups are separated by grey bars."
                     "",
                     ""
                 ],
                 anchor="middle"
             ),
             config=alt.Config(
                 view=alt.ViewConfig(width=600),
                 legend=alt.LegendConfig(titleFontSize=12, labelFontSize=12),
                 axis=alt.AxisConfig(titleFontSize=12, titleFontWeight="normal")
             )
         )

         with open(output[0], "w") as f:
             f.write(chart.to_json(indent=None))
             f.flush()
