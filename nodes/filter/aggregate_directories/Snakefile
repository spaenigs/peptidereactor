from pathos.multiprocessing import ProcessingPool as Pool
from more_itertools import chunked
from functools import partial
from glob import glob

import numpy as np

import os

TOKEN = config["token"]

rule all:
    input:
         f"data/temp/{TOKEN}/dirs_aggregated.txt"

rule copy_files:
    input:
         config["dirs_in"]
    output:
         temp(f"data/temp/{TOKEN}/dirs_aggregated.txt")
    run:
         def filter_files(from_files, target_dir):
             for csv_path in from_files:
                 if os.path.getsize(csv_path) == 0:
                     continue
                 else:
                     shell(f"cp {csv_path} {target_dir}")

         def run(from_files, target_dir):
             cores = workflow.cores
             p = Pool(cores)
             chunk_len = int(np.round(len(from_files)/cores))
             if chunk_len == 0:
                 chunk_len = 1
             chunks = chunked(from_files, chunk_len)
             pfunc = partial(filter_files, target_dir=target_dir)
             p.map(pfunc, chunks)

         for d in list(input):
             run(glob(d + "*.csv"), config["dir_out"])

         shell("touch {output}")