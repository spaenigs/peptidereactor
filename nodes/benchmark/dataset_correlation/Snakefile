from glob import glob
from itertools import combinations
from more_itertools import chunked

import pandas as pd
import numpy as np

import yaml

"./peptidereactor/run_pipeline -s nodes/benchmark/dataset_correlation/Snakefile --config token=asd metrics_dir_in=data/ace_vaxinpad/benchmark/metrics/ dataset_corr_out=data/temp/asd/ds.csv group_1_in=data/ace_vaxinpad/csv/sequence_based/ group_2_in=data/ace_vaxinpad/csv/structure_based/ --cores 1 --quiet -nr"

TOKEN = config["token"]

df_f1 = pd.read_csv(config["metrics_dir_in"] + "f1.csv", index_col=0)
medians = df_f1.apply(np.median).sort_values(ascending=False)

files_seq_based_filtered = \
    [config["group_1_in"] + f"{i}.csv" for i in medians.index[:50] \
     if config["group_1_in"] + f"{i}.csv" in glob(config["group_1_in"] + "*.csv")]

FILES = \
    files_seq_based_filtered + \
    glob(config["group_2_in"] + "*.csv")

FILES_PRODUCT_1, FILES_PRODUCT_2 = \
    zip(*combinations(FILES, 2))

FROMs, TOs = \
    zip(*[(c[0], c[-1]+1) for c in chunked(range(len(FILES_PRODUCT_1)), 70)])

rule all:
    input:
         config["dataset_corr_out"]

rule split_batches:
    output:
         f"data/temp/{TOKEN}/batch_{{fr}}_{{to}}.yaml"
    run:
         fr, to = int(wildcards.fr), int(wildcards.to)

         res = []
         for f1, f2 in zip(FILES_PRODUCT_1[fr:to], FILES_PRODUCT_2[fr:to]):
            res += [[f1, f2]]

         with open(output[0], "w") as f:
             yaml.safe_dump(res, f)

rule compute_dataset_correlation:
    input:
         f"data/temp/{TOKEN}/batch_{{fr}}_{{to}}.yaml"
    output:
         f"data/temp/{TOKEN}/dataset_correlation_{{fr}}_{{to}}.csv"
    params:
         cores=workflow.cores
    script:
         "scripts/dataset_correlation.R"

rule collect:
    input:
         expand(f"data/temp/{TOKEN}/dataset_correlation_{{fr}}_{{to}}.csv",
                 zip, fr=FROMs, to=TOs)
    output:
         config["dataset_corr_out"]
    run:
         df_res = pd.DataFrame()
         for p in list(input):
             df_res = pd.concat([df_res, pd.read_csv(p, index_col=0)])

         df_res.index = range(0, df_res.shape[0])
         df_res.to_csv(output[0])
