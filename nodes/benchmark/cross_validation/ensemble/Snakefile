from functools import reduce
from glob import glob

import pandas as pd

import os

TOKEN = config["token"]

CSV_SEQ_DIR = config["csv_seq_in"]
CSVS_SEQ_IN = glob(config["csv_seq_in"] + "*.csv")[:1]

CSV_STR_DIR = config["csv_str_in"]
CSVS_STR_IN = glob(config["csv_str_in"] + "*.csv")[:1]

NAMES_SEQ = [os.path.basename(p).replace(".csv", "") for p in CSVS_SEQ_IN]
NAMES_STR = [os.path.basename(p).replace(".csv", "") for p in CSVS_STR_IN]

rule all:
    input:
         expand(config["cv_dir_out"] + f"y_true_cv_{{name}}.csv", name=NAMES_SEQ),
         expand(config["cv_dir_out"] + f"y_pred_cv_{{name}}.csv", name=NAMES_SEQ),
         expand(config["cv_dir_out"] + f"y_prob_cv_{{name}}.csv", name=NAMES_SEQ),
         expand(config["cv_dir_out"] + f"y_true_cv_{{name}}.csv", name=NAMES_STR),
         expand(config["cv_dir_out"] + f"y_pred_cv_{{name}}.csv", name=NAMES_STR),
         expand(config["cv_dir_out"] + f"y_prob_cv_{{name}}.csv", name=NAMES_STR)

rule get_unique_ids:
    input:
         config["csv_str_in"]
    output:
         f"data/temp/{TOKEN}/filtered_struc_based_ids.txt"
    run:
         sets = [set(pd.read_csv(p, index_col=0).index.values)
                 for p in glob("data/hiv_protease/csv/structure_based/*.csv")]
         unique_ids = sorted(reduce(set.intersection, sets),
                             key=lambda v: int(v.replace("Seq_", "")))

         with open(output[0], "w") as f:
             for i in unique_ids:
                 f.write(f"{i}\n")
                 f.flush()

def filter_encodings(path_ids, path_in, path_out):
    df = pd.read_csv(path_in, index_col=0)
    with open(path_ids) as f:
        unique_ids = [i.rstrip() for i in f.readlines()]
    df.loc[unique_ids, :].to_csv(path_out)

rule filter_sequence_based_encodings:
    input:
         f"{CSV_SEQ_DIR}{{name}}.csv",
         f"data/temp/{TOKEN}/filtered_struc_based_ids.txt"
    output:
         f"data/temp/{TOKEN}/{{name}}.csv"
    run:
         # import pydevd_pycharm
         # pydevd_pycharm.settrace('localhost', port=8889, stdoutToServer=True, stderrToServer=True)
         filter_encodings(input[1], input[0], output[0])

rule filter_structure_based_encodings:
    input:
         f"{CSV_STR_DIR}{{name}}.csv",
         f"data/temp/{TOKEN}/filtered_struc_based_ids.txt"
    output:
         f"data/temp/{TOKEN}/{{name}}.csv"
    run:
         filter_encodings(input[1], input[0], output[0])

rule train:
    input:
         f"data/temp/{TOKEN}/{{name}}.csv"
    output:
         config["cv_dir_out"] + f"y_true_cv_{{name}}.csv",
         config["cv_dir_out"] + f"y_pred_cv_{{name}}.csv",
         config["cv_dir_out"] + f"y_prob_cv_{{name}}.csv"
    script:
         "../scripts/cv.py"