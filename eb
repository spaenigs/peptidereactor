#!/usr/bin/env python

import yaml
import os
import glob
import sys
import re
import itertools, more_itertools

from snakemake import shell
from shutil import copyfile, rmtree


class Snakemake:

    @staticmethod
    def __set_shell_cmd(file_len):
        cmds = [f"cp {{input[{i}]}} {{output[{i}]}}"
                for i in range(0, file_len)]
        return [f"\"{x}\"" for x in ["; ".join(cmds)]]

    @staticmethod
    def __set_smk_file(in_files_dict, out_files_dict):
        len_in_files, len_out_files = len(in_files_dict.keys()), len(out_files_dict.keys())
        rules = [{"all": {"input": [f"config['{k}']" for k in out_files_dict.keys()]}},
                 {"init": {"input": [f"config['{k}']" for k in in_files_dict.keys()],
                           "output": ["temp(\"*\")" for i in range(len_in_files)],
                           "shell": Snakemake.__set_shell_cmd(len_in_files)}},
                 {"exit": {"input": ["\"*\"" for i in range(len_out_files)],
                           "output": [f"config['{k}']" for k in out_files_dict.keys()],
                           "shell": Snakemake.__set_shell_cmd(len_out_files)}}]
        return rules

    def dump(self, dst):
        with open(dst, mode="a") as f:
            for rule_dict in self.smk_file:
                rule = list(rule_dict.keys())[0]
                f.write(f"rule {rule}:\n")
                f.flush()
                for k in rule_dict[rule].keys():
                    f.write(" " * 4 + f"{k}:\n")
                    f.flush()
                    len_i = len(rule_dict[rule][k])
                    for i, content in zip(range(len_i), rule_dict[rule][k]):
                        f.write(" " * 8 + f"{content}{',' if (i + 1) < len_i else ''}\n")
                        f.flush()
                f.write("\n")
                f.flush()


    def __init__(self, in_file_keys, out_file_keys):
        self.smk_file = self.__set_smk_file(in_file_keys, out_file_keys)


class Node:

    @staticmethod
    def __parse_yaml(path):
        with open(path) as stream:
            y = yaml.safe_load(stream)
        return y

    def dump(self):
        node_path = f"{self.node_root}/{self.node_group}/{self.node_name}"
        smk_path = node_path + "/snakemake"
        try:
            os.makedirs(node_path)
        except FileExistsError:
            print("Node already existing...")
            sys.exit(0)
        copyfile(self.yaml_path, node_path + "/node.yaml")
        try:
            os.mkdir(smk_path)
        except FileExistsError:
            print("Directory 'snakemake' already existing...")
            sys.exit(0)
        self.snakemake.dump(smk_path + "/Snakefile")

    def __init__(self, node_yaml, node_root):
        self.yaml_path = node_yaml
        self.node_root = node_root
        self.config = self.__parse_yaml(node_yaml)
        self.node_name = self.config["node_name"]
        self.node_group = self.config["node_group"]
        self.snakemake = Snakemake(self.config["input"], self.config["output"])


class Executor:

    @staticmethod
    def __parse_yaml(path):
        with open(path) as stream:
            y = yaml.safe_load(stream)
        return y

    @staticmethod
    def __check_input_files(node_name, required_files, data_dir):
        # is_ = (os.path.basename(p) for p in glob.glob(data_dir + "/*"))
        # if len(list(filter(lambda p: p in required_files, is_))) != len(required_files):
        if not all([os.path.exists(f"{data_dir}/{f}") for f in required_files]):
            raise FileNotFoundError(f"Node '{node_name}' requires the following "
                                    f"files to be present: {required_files}")

    @staticmethod
    def __check_output_files(files, data_dir):
        if len(files) == 1:
            files = list(more_itertools.flatten(files))
        print([os.path.exists(f"{data_dir}/{f}") for f in files])
        if all([os.path.exists(f"{data_dir}/{f}") for f in files]):
            return True
        return False

    @staticmethod
    def __get_files_str(files_dict):
        res = []
        for k, v in files_dict.items():
            if type(v) == str:
                res += [f"{k}=data/{v}"]
            else:
                res += [f"{k}=" + ",".join([f"data/{i}" for i in v])]
        return res


    def set_smk_params(self, smk_params):
        self.smk_params = smk_params

    def __replace_dataset_name(self, input_dict):
        for k in input_dict.keys():
            input_dict[k] = input_dict[k].replace("<dataset>", self.dataset)
        return input_dict

    def __replace_encoding_param_str(self, out_files_dict):
        for k in out_files_dict.keys():
            file_str = out_files_dict[k]
            groups = re.findall("(\[.*?\])", file_str)
            if len(groups) == 0:
                continue
            elif len(groups) == 1:
                g = groups[0]
                out_files_dict[k] = [file_str.replace(g, str(i)) for i in eval(g)]
            elif len(groups) > 1:
                res = [eval(g) for g in groups]
                files = []
                for trip in itertools.product(*res):
                    tmp = file_str
                    for tup in zip(re.findall("(\[.*?\])", file_str), trip):
                        tmp = tmp.replace(tup[0], str(tup[1]))
                    files += [tmp]
                out_files_dict[k] = files
            else:
                raise ValueError("Unknown parameter pattern observed in " + file_str)
        return out_files_dict

    def run(self, root_dir, script_dir, data_dir):
        y: dict = self.config
        for node in y["order"]:
            os.chdir(y["nodes"][node]["path"])
            with open("node.yaml", 'r') as stream:
                y_node = yaml.safe_load(stream)

            input_files_dict = self.__replace_dataset_name(y["nodes"][node]["input"])

            self.__check_input_files(node_name=y_node["node_name"],
                                     required_files=input_files_dict.values(),
                                     data_dir=data_dir)


            ## 1) replace dataset name
            output_files_dict = self.__replace_dataset_name(y["nodes"][node]["output"])

            ## 2) expand files, if necessary
            out_files_dict = self.__replace_encoding_param_str(output_files_dict)
            # print(out_files_dict)

            ## 3) get out files strings
            out_files_str = self.__get_files_str(output_files_dict)
            # print(out_files_str)


            if self.__check_output_files(output_files_dict.values(), data_dir):
                print(f"Output files for node '{y_node['node_name']}' are already present. Skipping...")
                os.chdir(root_dir)
                continue

            # in_files_str = self.__get_files_str(input_files_dict)
            #
            # shell(f"""source {script_dir}/setup.sh \
            #                  {y_node['node_group']} \
            #                  {y_node['node_name']}
            #           sh {script_dir}/exec.sh \
            #              {os.getcwd()} {root_dir} {self.db_dir} \
            #              '--config dataset={self.dataset} {in_files_str} {out_files_str} {self.smk_params}'""")

            os.chdir(root_dir)

    def __init__(self, project_yaml, dataset, smk_params):
        self.config = self.__parse_yaml(project_yaml)
        self.db_dir = self.config["db"]
        self.dataset = dataset
        self.smk_params = smk_params


if sys.argv[1] == "add":
    node_yaml_path, nodes = sys.argv[2:4]
    n = Node(node_yaml_path, nodes)
    n.dump()
elif sys.argv[1] == "rm":
    node_root, node_group, node_name = sys.argv[2:5]
    if input(f"Delete node {node_root}/{node_group}/{node_name}? [y/n]") == "y":
        rmtree(f"{node_root}/{node_group}/{node_name}")
elif sys.argv[1] == "run":
   project_yaml, dataset, root_dir, smk_params = sys.argv[2:6]
   e = Executor(project_yaml, dataset, smk_params)
   e.run(root_dir=root_dir,
         script_dir=root_dir + "/scripts",
         data_dir=root_dir + "/data")
else:
    print("Unknown program: " + sys.argv[1])
